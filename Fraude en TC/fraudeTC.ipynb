{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulacion de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualizacion\n",
    "import missingno as miss\n",
    "\n",
    "#Funciones creadas\n",
    "from funciones import *\n",
    "\n",
    "#Evitar Warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy y RMSLE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Modelos utilizados\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"fraude_tc.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n"
     ]
    }
   ],
   "source": [
    "csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las correlaciones de la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_from_home                0.187571\n",
       "distance_from_last_transaction    0.091917\n",
       "ratio_to_median_purchase_price    0.462305\n",
       "repeat_retailer                  -0.001357\n",
       "used_chip                        -0.060975\n",
       "used_pin_number                  -0.100293\n",
       "online_order                      0.191973\n",
       "fraud                             1.000000\n",
       "Name: fraud, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.corr()['fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos las 4 columnas con mayor correlacion (se usaron 4 porque se obtiene la menor cantidad de Falsos Negativos, se busca esto por ser un caso de fraudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csv[csv.corr()['fraud'].sort_values(ascending=False).index[1:5]]\n",
    "\n",
    "y = csv['fraud']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide la informacion en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos 6 modelos distintos para ver los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_class = {\n",
    "    \"Logit\": LogisticRegression(),\n",
    "    \"DecTree\": DecisionTreeClassifier(),\n",
    "    \"RFC\": RandomForestClassifier(max_depth=5),\n",
    "    \"AdaBoostC\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Logit\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[180147   2081]\n",
      " [  9471   8301]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.94385    0.94363125 0.944275   0.9435125  0.9436    ]\n",
      "Media de cross_validation 0.9437737499999999\n",
      "RMSLE : 0.16658621216629937\n",
      "Accuracy de Test : 0.94224\n",
      "\n",
      "\n",
      "Modelo DecTree\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[179065   3163]\n",
      " [  3362  14410]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.96731875 0.96756875 0.96865    0.96780625 0.96813125]\n",
      "Media de cross_validation 0.9678949999999998\n",
      "RMSLE : 0.12519895997603703\n",
      "Accuracy de Test : 0.967375\n",
      "\n",
      "\n",
      "Modelo RFC\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[177847   4381]\n",
      " [   481  17291]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.97534375 0.97539375 0.97626875 0.97526875 0.9751125 ]\n",
      "Media de cross_validation 0.9754775\n",
      "RMSLE : 0.10807318246610245\n",
      "Accuracy de Test : 0.97569\n",
      "\n",
      "\n",
      "Modelo AdaBoostC\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[180804   1424]\n",
      " [  4611  13161]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.96924375 0.96998125 0.970475   0.9696875  0.96981875]\n",
      "Media de cross_validation 0.96984125\n",
      "RMSLE : 0.12040626933420755\n",
      "Accuracy de Test : 0.969825\n",
      "\n",
      "\n",
      "Modelo XGBoost\n",
      "\n",
      "\n",
      "[20:14:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Confusion Matrix\n",
      "\n",
      "[[177780   4448]\n",
      " [   441  17331]]\n",
      "\n",
      "\n",
      "[20:17:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:20:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:23:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:25:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:27:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Metricas cross_validation [0.975825   0.97595625 0.97634375 0.97545    0.975425  ]\n",
      "Media de cross_validation 0.9757999999999999\n",
      "RMSLE : 0.10837284680781635\n",
      "Accuracy de Test : 0.975555\n",
      "\n",
      "\n",
      "Modelo LightGBM\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[177739   4489]\n",
      " [   489  17283]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.97559375 0.97584375 0.97563125 0.97459375 0.9745375 ]\n",
      "Media de cross_validation 0.97524\n",
      "RMSLE : 0.10935481478391353\n",
      "Accuracy de Test : 0.97511\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in modelos_class.items():\n",
    "    print(\"Modelo\",name)\n",
    "    print(\"\\n\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion)\n",
    "    print(\"\\n\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Metricas cross_validation\", scores)\n",
    "    print(\"Media de cross_validation\", scores.mean())\n",
    "    print(f\"RMSLE :\",mean_squared_log_error(y_test, y_pred,squared=False))\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy de Test :\",accuracy)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos el modelo con mejor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[177739   4489]\n",
      " [   489  17283]]\n",
      "\n",
      "\n",
      "Metricas cross_validation [0.97559375 0.97584375 0.97563125 0.97459375 0.9745375 ]\n",
      "Media de cross_validation 0.97524\n",
      "RMSLE : 0.10935481478391353\n",
      "Accuracy de Test : 0.97511\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(task=\"train\",application=\"binary\")\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "print(\"\\n\")\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation\", scores)\n",
    "print(\"Media de cross_validation\", scores.mean())\n",
    "print(f\"RMSLE :\",mean_squared_log_error(y_test, y_pred,squared=False))\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy de Test :\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97bd01fe62e1fc55dc656bbce15621cfb80411fa9ef75cc4a438f2a333f4f694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
